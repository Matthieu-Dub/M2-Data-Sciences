{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYXhEqG-uC3z"
      },
      "source": [
        "# TP Coding a GAN in tensorflow/keras\n",
        "\n",
        "Author : Alasdair Newson\n",
        "\n",
        "alasdair.newson@telecom-paris.fr\n",
        "\n",
        "## Objective:\n",
        "\n",
        "The goal of this TP is to explore GANs applied to the mnist (and possibly cifar10) datasets.\n",
        "\n",
        "We will start with the mnist dataset.\n",
        "\n",
        "### Your task:\n",
        "You need to add the missing parts in the code (parts between # --- START CODE HERE and # --- END CODE HERE or # FILL IN CODE)\n",
        "\n",
        "First of all, let's load some packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "meKYIDlUysj6"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "import pickle\n",
        "import copy\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.autograd import Variable\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "def pytorch_to_numpy(x):\n",
        "  return x.detach().numpy()\n",
        "\n",
        "\n",
        "# Decide which device we want to run on\n",
        "if (torch.cuda.is_available()):\n",
        "  device = torch.device(\"cuda:0\")\n",
        "else:\n",
        "  device = \"cpu\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgTDA2KIG4Vm"
      },
      "source": [
        "## Loading the data\n",
        "\n",
        "We define a function to load the mnist or cifar10 datasets. Note, we normalise the data between -1 and 1 here (this is often the case for GANs)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,),(0.5,)),\n",
        "])\n",
        "\n",
        "# MNIST Dataset\n",
        "mnist_trainset = datasets.MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
        "mnist_testset = datasets.MNIST(root='./mnist_data/', train=False, transform=transform, download=False)\n",
        "\n",
        "#create data loader with smaller dataset size\n",
        "max_mnist_size = 1000\n",
        "mnist_trainset_reduced = torch.utils.data.random_split(mnist_trainset, [max_mnist_size, len(mnist_trainset)-max_mnist_size])[0] \n",
        "mnist_train_loader = torch.utils.data.DataLoader(mnist_trainset_reduced, batch_size=64, shuffle=True)\n",
        "\n",
        "# download test dataset\n",
        "max_mnist_size = 512\n",
        "mnist_testset_reduced = torch.utils.data.random_split(mnist_testset, [max_mnist_size, len(mnist_testset)-max_mnist_size])[0] \n",
        "mnist_test_loader = torch.utils.data.DataLoader(mnist_testset_reduced, batch_size=64, shuffle=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "Kq9DHNlPiI3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_rows = mnist_trainset_reduced.dataset.train_data.shape[1]\n",
        "n_cols = mnist_trainset_reduced.dataset.train_data.shape[2]\n",
        "n_channels = 1\n",
        "n_pixels = n_rows*n_cols\n",
        "\n",
        "img_shape = (n_rows, n_cols, n_channels)"
      ],
      "metadata": {
        "id": "kpniDL3gekkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GAN parameters"
      ],
      "metadata": {
        "id": "h25SHO2dT_Uz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## GAN parameters\n",
        "z_dim = 10\n",
        "batch_size = 64\n",
        "## parameters for training\n",
        "n_epochs = 400\n",
        "n_iters_inner=1\t#number of internal loops\n",
        "sample_interval=100\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0002\n",
        "beta_1 = 0.5\n",
        "\n",
        "# hidden dimensions : careful, the order here is with respect to the generator, and the discriminator is in the opposite order\n",
        "h_dim_1 = 256\n",
        "h_dim_2 = 512"
      ],
      "metadata": {
        "id": "3l7szkgMT_3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi7BsXCsytEd"
      },
      "source": [
        "## Model architecture\n",
        "\n",
        "Now, we define the model architecture.\n",
        "\n",
        "For the first dataset, mnist, we are going to use fully connected layers. Implement the following architecture, for the generator and the discriminator :\n",
        "\n",
        "Generator :\n",
        "- Dense layer, to size 256\n",
        "- Leaky ReLU ($\\alpha=0.2$)\n",
        "- Dense layer, to size 512\n",
        "- Leaky ReLU ($\\alpha=0.2$)\n",
        "- Dense layer, output size 784\n",
        "- Tanh activation\n",
        "- Reshape to size $28 \\times 28 \\times 1$\n",
        "\n",
        "Discriminator :\n",
        "- Flatten\n",
        "- Dense layer, to size 512\n",
        "- Leaky ReLU ($\\alpha=0.2$)\n",
        "- Dense layer, output size 256\n",
        "- Leaky ReLU ($\\alpha=0.2$)\n",
        "- Dense layer, output size 1\n",
        "- Sigmoid activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "in24TH-RESPO"
      },
      "outputs": [],
      "source": [
        "# Generator Code\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, z_dim, h_dim_1, h_dim_2, n_rows,n_cols,n_channels):\n",
        "    super(Generator, self).__init__()\n",
        "    self.n_rows = n_rows\n",
        "    self.n_cols = n_cols\n",
        "    self.n_channels = n_channels\n",
        "    self.n_pixels = (self.n_rows)*(self.n_cols)\n",
        "    self.h_dim_1 = h_dim_1\n",
        "    self.h_dim_2 = h_dim_2\n",
        "    self.z_dim = z_dim\n",
        "\n",
        "    # START TO FILL IN\n",
        "    self.fc1 = ...\n",
        "    self.fc2 = ...\n",
        "    self.fc3 = ...\n",
        "    # END TO FILL IN\n",
        "\n",
        "  def forward(self, z):\n",
        "    # START TO FILL IN\n",
        "    y = ...\n",
        "    # END TO FILL IN\n",
        "    \n",
        "    return(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuXe9NVXOSnD"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, h_dim_2, h_dim_1, z_dim, n_rows,n_cols,n_channels):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.n_rows = n_rows\n",
        "    self.n_cols = n_cols\n",
        "    self.n_channels = n_channels\n",
        "    self.n_pixels = (self.n_rows)*(self.n_cols)\n",
        "    self.h_dim_1 = h_dim_1\n",
        "    self.h_dim_2 = h_dim_2\n",
        "    self.z_dim = z_dim\n",
        "\n",
        "    # START TO FILL IN\n",
        "    self.fc1 = ...\n",
        "    self.fc2 = ...\n",
        "    self.fc3 = ...\n",
        "    # END TO FILL IN\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = ...  # FILL IN HERE\n",
        "    return y\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create generator and discriminator "
      ],
      "metadata": {
        "id": "iq00Ve8OdOXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_model = Generator(...).to(device) # FILL IN HERE\n",
        "# Print the model\n",
        "print(gen_model)\n",
        "\n",
        "disc_model = Discriminator(...).to(device) # FILL IN HERE, CAREFUL OF ORDER OF PARAMETERS\n",
        "# Print the model\n",
        "print(disc_model)"
      ],
      "metadata": {
        "id": "FP5lYLacdNyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdznIctaESt-"
      },
      "source": [
        "## Loss function\n",
        "\n",
        "\n",
        "The GAN loss function is the following :\n",
        "\\begin{equation}\n",
        "\t\\min_{G} \\max_{D} \\mathbb{E}_{x \\in p_{data}} \\left[ \\log D(x)\\right] +\n",
        "\t\\mathbb{E}_{z \\in p_{z}}\\left[ \\log \\left( 1 - D(G(z)) \\right)\\right],\n",
        "\\end{equation}\n",
        "where $G$ is the generator, $D$ is the discriminator, $z$ is the latent code, which follows a normal distribution.\n",
        "\n",
        "You should notice that this is extremely similar to the binary cross-entropy function. Therefore, there is an intelligent way to train the discriminator : we give it first a batch of real images, and label them as real, and secondly we give a batch of fake images and label them as fake. Therefore, the discriminator training itself is done in two sequential steps (first true, then fake). If the labels are correctly chosen (further on, during training), you can (and __should__) use the binary cross-entropy function.\n",
        "\n",
        "The generator loss, however, must be specified as :\n",
        "- $mean(\\log(1-D(G(z))))$\n",
        "\n",
        "You can use the ```torch.mean``` function for this purpose.\n",
        "\n",
        "\n",
        "The training is carried out sequentially : first we execute a few training steps on the discriminator, and then one on the generator. Therefore, we use two loops : one to train the discriminator (the internal loop) and one to train the generator (external loop, ie. the number of epochs). The GAN training algorithm is as follows :\n",
        "\n",
        "- For $i=0$ to $n-1$\n",
        "  - For $j=0$ to $m-1$\n",
        "    - $x \\leftarrow$ random batch of data\n",
        "    - $z \\leftarrow$ random batch of latent codes\n",
        "    - Train discriminator on real images $x$\n",
        "    - Train discriminator on fake images $G(z)$\n",
        "  - $z \\leftarrow$ random batch of latent codes\n",
        "  - Train discriminator on fake images $G(z)$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbnxHkOsuDOh"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizer_disc = optim.Adam(disc_model.parameters(), lr=lr, betas=(beta_1, 0.999))\n",
        "optimizer_gen = optim.Adam(gen_model.parameters(), lr=lr, betas=(beta_1, 0.999))\n",
        "\n",
        "# criterion used for the discriminator loss\n",
        "bce_criterion = ...  # FILL IN CODE\n",
        "\n",
        "# criterion used for the generator loss\n",
        "def loss_fn_gen(d_gen_data):\n",
        "  loss_gen = ...  # FILL IN CODE\n",
        "  return loss_gen\n",
        "\n",
        "\t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Z0IzHPlLLtb"
      },
      "source": [
        "### Sampling function\n",
        "\n",
        "We now create a function to sample several images during training (to follow the convergence of the network)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6oaCO17ZGzWN"
      },
      "outputs": [],
      "source": [
        "\n",
        "def sample_images(generator,z_dim, rand_seed=30):\n",
        "  #np.random.seed(rand_seed)\n",
        "  r, c = 5, 5\n",
        "  z_random = torch.randn(r * c, 1, z_dim, dtype=torch.float, device=device) #np.random.normal(0, 1, (r * c, z_dim))\n",
        "  \n",
        "  gen_imgs = np.transpose( generator(z_random).cpu().detach().numpy() , (0,2,3,1))\n",
        "\n",
        "  # Rescale images 0 - 1\n",
        "  gen_imgs = 0.5 * gen_imgs + 0.5\n",
        "\n",
        "  fig, axs = plt.subplots(r, c)\n",
        "  cnt = 0\n",
        "  for i in range(r):\n",
        "    for j in range(c):\n",
        "      #black and white images\n",
        "      if(gen_imgs.shape[3] == 1):\n",
        "        axs[i,j].imshow(gen_imgs[cnt,:,:,0], cmap='gray')\n",
        "      elif(gen_imgs.shape[3] == 3):   #colour images\n",
        "        gen_imgs_temp = gen_imgs.copy()\n",
        "        gen_imgs_temp = 255.*np.clip(gen_imgs_temp,0.0,1.0) \n",
        "        axs[i,j].imshow(gen_imgs_temp[cnt, :,:,:].astype(np.uint8))\n",
        "      else:\n",
        "        print('Error, unsupported channel size. Dude, I don''t know what you want me to do.\\\n",
        "            I can''t handle this data. You''ve made me very sad ...')\n",
        "      axs[i,j].axis('off')\n",
        "      cnt += 1\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfcwQGo7G0zA"
      },
      "source": [
        "## Training\n",
        "\n",
        "We are now ready to train the network. Here is the training algorithm again :\n",
        "\n",
        "- For $i=0$ to $n_{epochs}-1$\n",
        "  - For $j=0$ to $n_{iters\\_inner}-1$\n",
        "    - $x \\leftarrow$ random batch of data\n",
        "    - $z \\leftarrow$ random batch of latent codes\n",
        "    - Train discriminator on real images $x$\n",
        "    - Train discriminator on fake images $G(z)$\n",
        "  - $z \\leftarrow$ random batch of latent codes\n",
        "  - Train discriminator on fake images $G(z)$\n",
        "\n",
        "You can use ```torch.randn``` to create a batch of random Gaussian latent codes:\n",
        "- ```torch.randn(dim_1, dim_2, dim_3, device=device)```\n",
        "where ```dim_1, dim_2, dim_3``` are the dimensions of the Tensor.\n",
        "\n",
        "To create a batch of labels equal to 1, use the following function:\n",
        "- ```torch.ones(my_shape, dtype=torch.float, device=device)```\n",
        "where ```my_shape``` is the shape of the tensor of ones that you wish. \n",
        "\n",
        "Similarly, to create a batch of zeros, use:\n",
        "- ```torch.zeros(my_shape, dtype=torch.float, device=device)```"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)"
      ],
      "metadata": {
        "id": "TIZVW79aU0CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLk9cmsQLL--"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Training Loop\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "\n",
        "sample_interval=25\n",
        "\n",
        "print(\"Starting Training\")\n",
        "# For each epoch\n",
        "for epoch in range(n_epochs):\n",
        "  # For each batch in the dataloader\n",
        "  for i, data in enumerate(mnist_train_loader, 0):\n",
        "    for iter_inner in range(0,n_iters_inner):\n",
        "        \n",
        "      ############################\n",
        "      ### Train discriminator\n",
        "      ############################\n",
        "      ## Train with true data batch\n",
        "      disc_model.zero_grad()\n",
        "      # create true data and labels \n",
        "      true_imgs = data[0].to(device)\n",
        "      true_labels = ... # FILL IN HERE. CAREFUL, WE WANT A 1-DIMENSIONAL TENSOR OF LABELS (DUE TO THE \"VIEW\" IN NEXT LINE)\n",
        "      # put true data through discriminator\n",
        "      d_output_true = disc_model(...).view(-1) # FILL IN HERE\n",
        "      # bce loss on true data\n",
        "      d_loss_true = ... # FILL IN HERE\n",
        "      # backpropagation for discriminator, true loss\n",
        "      d_loss_true.backward()\n",
        "      disc_true_value = d_output_true.mean().item()\n",
        "\n",
        "      ## Train with fake data batch\n",
        "      # create fake data and labels\n",
        "      # generate batch of random latent vectors\n",
        "      z_latent_noise = ... # FILL IN HERE\n",
        "      # Generate batch of fake images\n",
        "      fake_imgs = ...  # FILL IN HERE\n",
        "      fake_labels = ... # FILL IN HERE\n",
        "      # put fake data through discriminator\n",
        "      disc_output_fake = disc_model(fake_imgs.detach()).view(-1)\n",
        "      # bce loss on fake data\n",
        "      disc_loss_fake = ...  # FILL IN HERE\n",
        "      # backpropagation for discriminator, fake loss\n",
        "      disc_loss_fake.backward()\n",
        "      disc_fake_value = disc_output_fake.mean().item()\n",
        "      # Update discriminator\n",
        "      optimizer_disc.step()\n",
        "\n",
        "      d_loss_total = d_loss_true+disc_loss_fake\n",
        "\n",
        "    ############################\n",
        "    ### Train generator\n",
        "    ############################\n",
        "    gen_model.zero_grad()\n",
        "    # We have updated the discriminator, so we need to update the output of the discriminator\n",
        "    disc_gen_output_fake = disc_model(...).view(-1) # FILL IN HERE\n",
        "    # Generator loss, using the custom loss\n",
        "    g_loss = loss_fn_gen(...) # FILL IN HERE\n",
        "    # backpropagation for generator\n",
        "    g_loss.backward()\n",
        "    #D_G_z2 = output.mean().item()\n",
        "    # Update generator\n",
        "    optimizer_gen.step()\n",
        "\n",
        "    # Output training stats\n",
        "    if i % 200 == 0:\n",
        "      print('[%d/%d][%d/%d] \\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f'\n",
        "      % (epoch, n_epochs, i, len(mnist_train_loader),d_loss_total.item(), g_loss.item(), disc_true_value, disc_fake_value ))\n",
        "\n",
        "    # Save Losses for plotting later\n",
        "    G_losses.append(g_loss.item())\n",
        "    D_losses.append(d_loss_total.item())\n",
        "\n",
        "\n",
        "  if(epoch % sample_interval == 0):\n",
        "    sample_images(gen_model,z_dim, rand_seed=30)\n",
        "\n",
        "# end samples\n",
        "sample_images(gen_model,z_dim, rand_seed=30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hopefully, you have managed to get the GAN working. Yoohoo !! You should notice that the results are much less smooth than those of the variational autoencoder. This is normal, in general a GAN produces sharper results, but is quite difficult to get working well. You can try and modify the latent space to see whether this improves the results."
      ],
      "metadata": {
        "id": "HAxaGxO6w8op"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKRGvUZaVWK3"
      },
      "source": [
        "# Training on CIFAR\n",
        "\n",
        "If you want to try another, more challenging database, use the above code and modify it to carry out the GAN training on the CIFAR10 database. Note, it can take a long time to get good results\n",
        "\n",
        "First, we download the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97W-qqT0GtaE"
      },
      "outputs": [],
      "source": [
        "# convert input to Pytorch tensors\n",
        "transform = transforms.Compose([\n",
        "                                transforms.ToTensor(),\n",
        "                                transforms.Normalize((0.5,),(0.5,)),\n",
        "])\n",
        "\n",
        "# extract mnist data\n",
        "cifar_trainset = datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\n",
        "print(cifar_trainset)\n",
        "\n",
        "#create data loader with smaller dataset size\n",
        "max_cifar_size = 2000\n",
        "cifar_trainset_reduced = torch.utils.data.random_split(cifar_trainset, [max_cifar_size, len(cifar_trainset)-max_cifar_size])[0] \n",
        "cifar_train_loader = torch.utils.data.DataLoader(cifar_trainset_reduced, batch_size=64, shuffle=True)\n",
        "\n",
        "# download test dataset\n",
        "cifar_testset = datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)\n",
        "cifar_test_loader = torch.utils.data.DataLoader(cifar_testset, batch_size=64, shuffle=True)\n",
        "\n",
        "n_rows = 32\n",
        "n_cols = 32\n",
        "n_channels = 3\n",
        "n_pixels = n_rows*n_cols\n",
        "\n",
        "img_shape = (n_rows, n_cols, n_channels)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can redefine the hyper-parameters of the model (change if you wish)"
      ],
      "metadata": {
        "id": "zxhv31g6NYMS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## GAN parameters\n",
        "z_dim = 10\n",
        "batch_size = 64\n",
        "n_epochs = 300\n",
        "## parameters for training\n",
        "n_iters_inner=1\t#number of internal loops\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0002\n",
        "beta_1 = 0.5"
      ],
      "metadata": {
        "id": "Vqp1dLHWNcY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this case of CIFAR, implement the following architecture :\n",
        "\n",
        "- Generator :\n",
        "  - Dense layer to size 1024\n",
        "  - Leaky ReLU ($\\alpha=0.2$)\n",
        "  - Reshape, to size $4 \\times 4 \\times64$\n",
        "  - % size = $4\\times4\\times64$\n",
        "  - Conv2d, n_channels=16,kernel size=(3,3), strides=(1,1),padding=(1,1)\n",
        "  - Upsample(scale_factor=(2,2))\n",
        "  - %size = $8\\times 8\\times 16$\n",
        "  - Leaky ReLU ($\\alpha=0.2$)\n",
        "  - Conv2d, n_channels=16,kernel size=(3,3), strides=(1,1),padding=(1,1)\n",
        "  - Upsample(scale_factor=(2,2))\n",
        "  - %size=$16 \\times 16 \\times 16$\n",
        "  - Leaky ReLU ($\\alpha=0.2$)\n",
        "  - Conv2d, n_channels=3,kernel size=(3,3), strides=(1,1),padding=(1,1)\n",
        "  - Upsample(scale_factor=(2,2))\n",
        "  - %size = $32 \\times 32 \\times 3$\n",
        "  - Tanh activation ( you can use ```Activation('tanh')```)\n",
        "\n",
        "- Discriminator :\n",
        "  - % input size : $32 \\times 32 \\times 3$\n",
        "  - Conv2D, 32 filters, kernel size = (3,3), strides = (1,1),padding = same\n",
        "  - % size $32 \\times 32 \\times 32$\n",
        "  - Leaky ReLU ($\\alpha=0.2$)\n",
        "  - Conv2D, 32 filters, kernel size = (3,3), strides = (2,2),padding = same\n",
        "  - %size : $16 \\times 16 \\times 32$\n",
        "  - Leaky ReLU ($\\alpha=0.2$)\n",
        "  - Conv2D, 64 filters, kernel size = (3,3), strides = (2,2),padding = same\n",
        "  - % size : $8 \\times 8 \\times 64$\n",
        "  - Leaky ReLU ($\\alpha=0.2$)\n",
        "  - Conv2D, 32 filters, kernel size = (3,3), strides = (2,2),padding = same\n",
        "  - % size : $4 \\times 4 \\times 32$\n",
        "  - Leaky ReLU ($\\alpha=0.2$)\n",
        "  - Flatten\n",
        "  - Dense layer to size 1\n",
        "  - Sigmoid activation\n",
        "\n",
        "  Implement this architecture below, and train the GAN. "
      ],
      "metadata": {
        "id": "EwUdFDCXNevC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator Code\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self, z_dim=10, h_dim_1=1024, n_channels_1=64, n_channels_2=16, n_channels_3=16,n_rows=32,n_cols=32,n_channels_out=3):\n",
        "    super(Generator, self).__init__()\n",
        "    self.n_rows = n_rows\n",
        "    self.n_cols = n_cols\n",
        "    self.n_channels_out = n_channels_out\n",
        "    self.n_pixels = (self.n_rows)*(self.n_cols)\n",
        "    self.z_dim = z_dim\n",
        "    self.h_dim_1=h_dim_1\n",
        "    self.n_channels_1= n_channels_1\n",
        "    self.n_channels_2 = n_channels_2\n",
        "    self.n_channels_3 = n_channels_3\n",
        "\n",
        "    self.fc1 = nn.Linear(z_dim, h_dim_1)\n",
        "    self.conv1 = nn.Conv2d(n_channels_1,n_channels_2,kernel_size=(3,3),padding=(1,1))\n",
        "    self.conv2 = nn.Conv2d(n_channels_2,n_channels_3,kernel_size=(3,3),padding=(1,1))\n",
        "    self.conv3 = nn.Conv2d(n_channels_3, n_channels_out,kernel_size=(3,3),padding=(1,1))\n",
        "  def forward(self, z):\n",
        "    y = nn.LeakyReLU(negative_slope=0.2)(self.fc1(z)).view(-1,self.n_channels_1,4,4)\n",
        "    # input shape : 4 x 4 x 64\n",
        "    y = nn.LeakyReLU(negative_slope=0.2)(self.conv1(y))\n",
        "    y = nn.Upsample(scale_factor=2, mode='bilinear')(y)\n",
        "    # input shape : 8 x 8 x 16\n",
        "    y = nn.LeakyReLU(negative_slope=0.2)(self.conv2(y))\n",
        "    y = nn.Upsample(scale_factor=2, mode='bilinear')( y )\n",
        "    # input shape : 16 x 16 x 16\n",
        "    y = nn.LeakyReLU(negative_slope=0.2)(self.conv3(y))\n",
        "    y = nn.Upsample(scale_factor=2, mode='bilinear')( y )\n",
        "    # input shape : 32 x 32 x 3\n",
        "    y = y.view(-1,self.n_channels_out,self.n_rows,self.n_cols)\n",
        "\n",
        "    return(y)\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, n_channels_3=16, n_channels_2=16, n_channels_1=64, h_dim_1=1024, z_dim=10,n_rows=32,n_cols=32,n_channels_in=3):\n",
        "    super(Discriminator, self).__init__()\n",
        "\n",
        "    self.n_rows = n_rows\n",
        "    self.n_cols = n_cols\n",
        "    self.n_channels_in = n_channels_in\n",
        "    self.n_pixels = (self.n_rows)*(self.n_cols)\n",
        "    self.z_dim = z_dim\n",
        "    self.h_dim_1=h_dim_1\n",
        "    self.n_channels_1= n_channels_1\n",
        "    self.n_channels_2 = n_channels_2\n",
        "    self.n_channels_3 = n_channels_3\n",
        "\n",
        "    self.conv1 = nn.Conv2d(self.n_channels_in,self.n_channels_3,kernel_size=(2,2),stride=(2,2))\n",
        "    self.conv2 = nn.Conv2d(self.n_channels_3,self.n_channels_2,kernel_size=(2,2),stride=(2,2))\n",
        "    self.conv3 = nn.Conv2d(self.n_channels_2, self.n_channels_1,kernel_size=(2,2),stride=(2,2))\n",
        "    self.fc1 = nn.Linear(self.h_dim_1,1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    y = nn.LeakyReLU(negative_slope=0.2)(self.conv1(x))\n",
        "    # input shape : 16 x 16 x 16\n",
        "    y = nn.LeakyReLU(negative_slope=0.2)(self.conv2(y))\n",
        "    # input shape : 8 x 8 x 16\n",
        "    y = nn.LeakyReLU(negative_slope=0.2)(self.conv3(y))\n",
        "    # input shape : 4 x 4 x 64\n",
        "    #flatten\n",
        "    y = y.view(-1,self.h_dim_1)\n",
        "    y = self.fc1(y)\n",
        "    y = nn.Sigmoid()(y)\n",
        "    return y\n",
        "\n",
        "\n",
        "gen_model = Generator(z_dim=z_dim, h_dim_1=1024, n_channels_1=64, n_channels_2=16, n_channels_3=16,n_rows=n_rows,n_cols=n_cols,n_channels_out=n_channels).to(device)\n",
        "# Print the model\n",
        "print(gen_model)\n",
        "\n",
        "disc_model = Discriminator(n_channels_3=16, n_channels_2=16, n_channels_1=64, h_dim_1=1024, z_dim=z_dim,n_rows=n_rows,n_cols=n_cols,n_channels_in=n_channels).to(device)\n",
        "# Print the model\n",
        "print(disc_model)\n",
        "  \n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizer_disc = optim.Adam(disc_model.parameters(), lr=lr, betas=(beta_1, 0.999))\n",
        "optimizer_gen = optim.Adam(gen_model.parameters(), lr=lr, betas=(beta_1, 0.999))\n",
        "\n",
        "bce_criterion = nn.BCELoss()\n"
      ],
      "metadata": {
        "id": "Q5m3--yiNhb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, carry out the training (use code above)"
      ],
      "metadata": {
        "id": "XGz2YT0KR2tX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "\n",
        "\n",
        "sample_interval=25\n",
        "\n",
        "print(\"Starting Training\")\n",
        "# For each epoch\n",
        "for epoch in range(n_epochs):\n",
        "  # For each batch in the dataloader\n",
        "  for i, data in enumerate(cifar_train_loader, 0):\n",
        "    for iter_inner in range(0,n_iters_inner):\n",
        "        \n",
        "      ############################\n",
        "      ### Train discriminator\n",
        "      ############################\n",
        "      ## Train with true data batch\n",
        "      disc_model.zero_grad()\n",
        "      # create true data and labels \n",
        "      true_imgs = data[0].to(device)\n",
        "      true_labels = torch.ones((true_imgs.shape[0],), dtype=torch.float, device=device)\n",
        "      # put true data through discriminator\n",
        "      d_output_true = disc_model(true_imgs).view(-1)\n",
        "      # bce loss on true data\n",
        "      d_loss_true = bce_criterion(d_output_true, true_labels)\n",
        "      # backpropagation for discriminator, true loss\n",
        "      d_loss_true.backward()\n",
        "      disc_true_value = d_output_true.mean().item()\n",
        "\n",
        "      ## Train with fake data batch\n",
        "      # create fake data and labels\n",
        "      # generate batch of random latent vectors\n",
        "      z_latent_noise = torch.randn(true_imgs.shape[0], 1, z_dim, device=device)\n",
        "      # Generate batch of fake images\n",
        "      fake_imgs = gen_model(z_latent_noise)\n",
        "      fake_labels = torch.zeros((fake_imgs.shape[0],), dtype=torch.float, device=device)\n",
        "      # put fake data through discriminator\n",
        "      disc_output_fake = disc_model(fake_imgs.detach()).view(-1)\n",
        "      # bce loss on fake data\n",
        "      disc_loss_fake = bce_criterion(disc_output_fake, fake_labels)\n",
        "      # backpropagation for discriminator, fake loss\n",
        "      disc_loss_fake.backward()\n",
        "      disc_fake_value = disc_output_fake.mean().item()\n",
        "      # Update discriminator\n",
        "      optimizer_disc.step()\n",
        "\n",
        "      d_loss_total = d_loss_true+disc_loss_fake\n",
        "\n",
        "    ############################\n",
        "    ### Train generator\n",
        "    ############################\n",
        "    gen_model.zero_grad()\n",
        "    # We have updated the discriminator, so we need to update the output of the discriminator\n",
        "    disc_gen_output_fake = disc_model(fake_imgs).view(-1)\n",
        "    # Generator loss, using the custom loss\n",
        "    g_loss = loss_fn_gen(disc_gen_output_fake)\n",
        "    # backpropagation for generator\n",
        "    g_loss.backward()\n",
        "    #D_G_z2 = output.mean().item()\n",
        "    # Update generator\n",
        "    optimizer_gen.step()\n",
        "\n",
        "    # Output training stats\n",
        "    if i % 200 == 0:\n",
        "      print('[%d/%d][%d/%d] \\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f'\n",
        "      % (epoch, n_epochs, i, len(cifar_train_loader),d_loss_total.item(), g_loss.item(), disc_true_value, disc_fake_value ))\n",
        "\n",
        "    # Save Losses for plotting later\n",
        "    G_losses.append(g_loss.item())\n",
        "    D_losses.append(d_loss_total.item())\n",
        "\n",
        "\n",
        "  if(epoch % sample_interval == 0):\n",
        "    sample_images(gen_model,z_dim, rand_seed=30)"
      ],
      "metadata": {
        "id": "dQcGMK7YR3JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GAP5fAZZTPMt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}